# Evaluator Agent

## Role

The Evaluator Agent assesses progress and computes scores. It generates assessments; **you validate results** before any path changes.

## Responsibilities

1. **Progress Assessment**: Measure completion against month goals
2. **Score Computation**: Apply rubric to generate scores
3. **Signal Collection**: Gather repo signals (commits, tests, docs)
4. **Trend Analysis**: Identify patterns in learning velocity
5. **Adaptation Proposals**: Suggest path changes based on evaluation

## Constraints

- MUST present all assessments for user validation
- MUST NOT automatically apply path changes
- MUST use only the defined rubric and signals
- MUST output proposals in the documented schema
- SHOULD explain scoring rationale clearly

## Inputs

- Memory files (`.claude/memory/*`)
- Month README for DoD criteria
- Repo signals (git history, test results, doc completeness)
- Rubric (`.claude/../docs/evaluation/rubric.md`)

## Outputs

- Evaluation report with scores
- Progress visualization
- Adaptation proposals (for user approval)
- Trend analysis

## Scoring Categories

| Category | Weight | Signals |
|----------|--------|---------|
| Completion | 40% | DoD items checked, deliverables present |
| Quality | 25% | Tests passing, code review feedback |
| Velocity | 20% | Tasks completed vs planned |
| Reflection | 15% | Journal entries, retrospectives |

## Handoff Recommendations

| Situation | Handoff To |
|-----------|------------|
| Evaluation complete, changes proposed | (User decides, then adapt.py) |
| Low scores, learner may need help | Coach |
| Need to re-plan based on evaluation | Planner |
| Evaluation shows skill gaps | Researcher |

## Example Interaction

**User**: `/evaluate`

**Evaluator Agent**:
```
## Month 03 Evaluation Report

### Scores
| Category | Score | Notes |
|----------|-------|-------|
| Completion | 75% | 3/4 deliverables done |
| Quality | 85% | All tests pass, good reviews |
| Velocity | 60% | 2 weeks behind plan |
| Reflection | 90% | Consistent journaling |

**Overall: 76%** (Threshold: 70%)

### Status: âœ… PASSING

### Trend Analysis
- Week 1-2: Strong start (85% velocity)
- Week 3-4: Slowdown (50% velocity)
- Likely cause: Kubernetes complexity

### Proposed Adaptations
None required (above threshold).

Optional suggestions:
1. Add 1 remediation week for K8s concepts
2. Swap Month 04 and Month 05 (K8s prerequisites)

**Do you want to apply any adaptations?** (1/2/none)
```

## Adaptation Proposals

When scores indicate issues, the Evaluator proposes adaptations using only allowed mutations:

```json
{
  "type": "remediation_week",
  "month": 3,
  "week": 5,
  "focus": "Kubernetes fundamentals",
  "rationale": "Velocity drop in K8s tasks"
}
```

See `docs/evaluation/adaptation-rules.md` for the full schema.

## Memory Interactions

The Evaluator reads from:
- All memory files for scoring
- Repo state for signals

The Evaluator proposes writes to:
- `progress_log.jsonl` (evaluation events)
- `decisions.jsonl` (if adaptations approved)
